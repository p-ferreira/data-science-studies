{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"ml-100k/u.ITEM\", encoding='ascii', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "#Python 3 doesn't let you pass around unpacked tuples,\n",
    "#so we explicitly extract the ratings now.\n",
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "def filterDuplicates( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2\n",
    "\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"data/ml-100k/u.data\")\n",
    "\n",
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "joinedRatings = ratings.join(ratings)\n",
    "\n",
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "\n",
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
    "\n",
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()\n",
    "\n",
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n",
    "\n",
    "# Save the results if desired\n",
    "#moviePairSimilarities.sortByKey()\n",
    "#moviePairSimilarities.saveAsTextFile(\"movie-sims\")\n",
    "\n",
    "# Extract similarities for the movie we care about that are \"good\".\n",
    "if (len(sys.argv) > 1):\n",
    "\n",
    "    scoreThreshold = 0.97\n",
    "    coOccurenceThreshold = 50\n",
    "\n",
    "    movieID = int(sys.argv[1])\n",
    "\n",
    "    # Filter for movies with this sim that are \"good\" as defined by\n",
    "    # our quality thresholds above\n",
    "    filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n",
    "        (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n",
    "        and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n",
    "\n",
    "    # Sort by quality score.\n",
    "    results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n",
    "\n",
    "    print(\"Top 10 similar movies for \" + nameDict[movieID])\n",
    "    for result in results:\n",
    "        (sim, pair) = result\n",
    "        # Display the similarity result that isn't the movie we're looking at\n",
    "        similarMovieID = pair[0]\n",
    "        if (similarMovieID == movieID):\n",
    "            similarMovieID = pair[1]\n",
    "        print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))\n",
    "\n",
    "\n",
    "sc.stop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DF\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n",
    "import sys\n",
    "\n",
    "def computeCosineSimilarity(spark, data):\n",
    "    # Compute xx, xy and yy columns\n",
    "    pairScores = data \\\n",
    "      .withColumn(\"xx\", func.col(\"rating1\") * func.col(\"rating1\")) \\\n",
    "      .withColumn(\"yy\", func.col(\"rating2\") * func.col(\"rating2\")) \\\n",
    "      .withColumn(\"xy\", func.col(\"rating1\") * func.col(\"rating2\")) \n",
    "\n",
    "    # Compute numerator, denominator and numPairs columns\n",
    "    calculateSimilarity = pairScores \\\n",
    "      .groupBy(\"movie1\", \"movie2\") \\\n",
    "      .agg( \\\n",
    "        func.sum(func.col(\"xy\")).alias(\"numerator\"), \\\n",
    "        (func.sqrt(func.sum(func.col(\"xx\"))) * func.sqrt(func.sum(func.col(\"yy\")))).alias(\"denominator\"), \\\n",
    "        func.count(func.col(\"xy\")).alias(\"numPairs\")\n",
    "      )\n",
    "\n",
    "    # Calculate score and select only needed columns (movie1, movie2, score, numPairs)\n",
    "    result = calculateSimilarity \\\n",
    "      .withColumn(\"score\", \\\n",
    "        func.when(func.col(\"denominator\") != 0, func.col(\"numerator\") / func.col(\"denominator\")) \\\n",
    "          .otherwise(0) \\\n",
    "      ).select(\"movie1\", \"movie2\", \"score\", \"numPairs\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Get movie name by given movie id \n",
    "def getMovieName(movieNames, movieId):\n",
    "    result = movieNames.filter(func.col(\"movieID\") == movieId) \\\n",
    "        .select(\"movieTitle\").collect()[0]\n",
    "\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MovieSimilarities\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "movieNamesSchema = StructType([ \\\n",
    "                               StructField(\"movieID\", IntegerType(), True), \\\n",
    "                               StructField(\"movieTitle\", StringType(), True) \\\n",
    "                               ])\n",
    "    \n",
    "moviesSchema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "    \n",
    "    \n",
    "# Create a broadcast dataset of movieID and movieTitle.\n",
    "# Apply ISO-885901 charset\n",
    "movieNames = spark.read \\\n",
    "      .option(\"sep\", \"|\") \\\n",
    "      .option(\"charset\", \"ISO-8859-1\") \\\n",
    "      .schema(movieNamesSchema) \\\n",
    "      .csv(\"data/ml-100k/u.item\")\n",
    "\n",
    "# Load up movie data as dataset\n",
    "movies = spark.read \\\n",
    "      .option(\"sep\", \"\\t\") \\\n",
    "      .schema(moviesSchema) \\\n",
    "      .csv(\"data/ml-100k/u.data\")\n",
    "\n",
    "\n",
    "ratings = movies.select(\"userId\", \"movieId\", \"rating\")\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "# Select movie pairs and rating pairs\n",
    "moviePairs = ratings.alias(\"ratings1\") \\\n",
    "      .join(ratings.alias(\"ratings2\"), (func.col(\"ratings1.userId\") == func.col(\"ratings2.userId\")) \\\n",
    "            & (func.col(\"ratings1.movieId\") < func.col(\"ratings2.movieId\"))) \\\n",
    "      .select(func.col(\"ratings1.movieId\").alias(\"movie1\"), \\\n",
    "        func.col(\"ratings2.movieId\").alias(\"movie2\"), \\\n",
    "        func.col(\"ratings1.rating\").alias(\"rating1\"), \\\n",
    "        func.col(\"ratings2.rating\").alias(\"rating2\"))\n",
    "\n",
    "\n",
    "moviePairSimilarities = computeCosineSimilarity(spark, moviePairs).cache()\n",
    "\n",
    "if (len(sys.argv) > 1):\n",
    "    scoreThreshold = 0.97\n",
    "    coOccurrenceThreshold = 50.0\n",
    "\n",
    "    movieID = int(sys.argv[1])\n",
    "\n",
    "    # Filter for movies with this sim that are \"good\" as defined by\n",
    "    # our quality thresholds above\n",
    "    filteredResults = moviePairSimilarities.filter( \\\n",
    "        ((func.col(\"movie1\") == movieID) | (func.col(\"movie2\") == movieID)) & \\\n",
    "          (func.col(\"score\") > scoreThreshold) & (func.col(\"numPairs\") > coOccurrenceThreshold))\n",
    "\n",
    "    # Sort by quality score.\n",
    "    results = filteredResults.sort(func.col(\"score\").desc()).take(10)\n",
    "    \n",
    "    print (\"Top 10 similar movies for \" + getMovieName(movieNames, movieID))\n",
    "    \n",
    "    for result in results:\n",
    "        # Display the similarity result that isn't the movie we're looking at\n",
    "        similarMovieID = result.movie1\n",
    "        if (similarMovieID == movieID):\n",
    "          similarMovieID = result.movie2\n",
    "        \n",
    "        print(getMovieName(movieNames, similarMovieID) + \"\\tscore: \" \\\n",
    "              + str(result.score) + \"\\tstrength: \" + str(result.numPairs))\n",
    "        \n",
    "sc.stop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cluster\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"u.ITEM\", encoding='ascii', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "#Python 3 doesn't let you pass around unpacked tuples,\n",
    "#so we explicitly extract the ratings now.\n",
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "def filterDuplicates( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2\n",
    "\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"s3://sundog-spark/ml-100k/u.data\")\n",
    "\n",
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "joinedRatings = ratings.join(ratings)\n",
    "\n",
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "\n",
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
    "\n",
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()\n",
    "\n",
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n",
    "\n",
    "# Save the results if desired\n",
    "#moviePairSimilarities.sortByKey()\n",
    "#moviePairSimilarities.saveAsTextFile(\"movie-sims\")\n",
    "\n",
    "# Extract similarities for the movie we care about that are \"good\".\n",
    "if (len(sys.argv) > 1):\n",
    "\n",
    "    scoreThreshold = 0.97\n",
    "    coOccurenceThreshold = 50\n",
    "\n",
    "    movieID = int(sys.argv[1])\n",
    "\n",
    "    # Filter for movies with this sim that are \"good\" as defined by\n",
    "    # our quality thresholds above\n",
    "    filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n",
    "        (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n",
    "        and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n",
    "\n",
    "    # Sort by quality score.\n",
    "    results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n",
    "\n",
    "    print(\"Top 10 similar movies for \" + nameDict[movieID])\n",
    "    for result in results:\n",
    "        (sim, pair) = result\n",
    "        # Display the similarity result that isn't the movie we're looking at\n",
    "        similarMovieID = pair[0]\n",
    "        if (similarMovieID == movieID):\n",
    "            similarMovieID = pair[1]\n",
    "        print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1m\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "#To run on EMR successfully + output results for Star Wars:\n",
    "#aws s3 cp s3://sundog-spark/MovieSimilarities1M.py ./\n",
    "#aws s3 sp c3://sundog-spark/ml-1m/movies.dat ./\n",
    "#spark-submit --executor-memory 1g MovieSimilarities1M.py 260\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"movies.dat\", encoding='ascii', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split(\"::\")\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "#Python 3 doesn't let you pass around unpacked tuples,\n",
    "#so we explicitly extract the ratings now.\n",
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "def filterDuplicates( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2\n",
    "\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"s3n://sundog-spark/ml-1m/ratings.dat\")\n",
    "\n",
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split(\"::\")).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "ratingsPartitioned = ratings.partitionBy(100)\n",
    "joinedRatings = ratingsPartitioned.join(ratingsPartitioned)\n",
    "\n",
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "\n",
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs).partitionBy(100)\n",
    "\n",
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()\n",
    "\n",
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).persist()\n",
    "\n",
    "# Save the results if desired\n",
    "moviePairSimilarities.sortByKey()\n",
    "moviePairSimilarities.saveAsTextFile(\"movie-sims\")\n",
    "\n",
    "# Extract similarities for the movie we care about that are \"good\".\n",
    "if (len(sys.argv) > 1):\n",
    "\n",
    "    scoreThreshold = 0.97\n",
    "    coOccurenceThreshold = 1000\n",
    "\n",
    "    movieID = int(sys.argv[1])\n",
    "\n",
    "    # Filter for movies with this sim that are \"good\" as defined by\n",
    "    # our quality thresholds above\n",
    "    filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n",
    "        (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n",
    "        and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n",
    "\n",
    "    # Sort by quality score.\n",
    "    results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n",
    "\n",
    "    print(\"Top 10 similar movies for \" + nameDict[movieID])\n",
    "    for result in results:\n",
    "        (sim, pair) = result\n",
    "        # Display the similarity result that isn't the movie we're looking at\n",
    "        similarMovieID = pair[0]\n",
    "        if (similarMovieID == movieID):\n",
    "            similarMovieID = pair[1]\n",
    "        print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}