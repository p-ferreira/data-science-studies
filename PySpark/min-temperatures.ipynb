{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# RDD\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"MinTemperatures\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
    "    return (stationID, entryType, temperature)\n",
    "\n",
    "lines = sc.textFile(\"data/1800.csv\")\n",
    "parsedLines = lines.map(parseLine)\n",
    "minTemps = parsedLines.filter(lambda x: \"TMIN\" in x[1])\n",
    "stationTemps = minTemps.map(lambda x: (x[0], x[2]))\n",
    "minTemps = stationTemps.reduceByKey(lambda x, y: min(x,y))\n",
    "results = minTemps.collect();\n",
    "\n",
    "for result in results:\n",
    "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ITE00100554\t5.36F\n",
      "EZE00100082\t7.70F\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#DF\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MinTemperatures\").getOrCreate()\n",
    "\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"stationID\", StringType(), True), \\\n",
    "                     StructField(\"date\", IntegerType(), True), \\\n",
    "                     StructField(\"measure_type\", StringType(), True), \\\n",
    "                     StructField(\"temperature\", FloatType(), True)])\n",
    "\n",
    "# // Read the file as dataframe\n",
    "df = spark.read.schema(schema).csv(\"data/1800.csv\")\n",
    "df.printSchema()\n",
    "\n",
    "# Filter out all but TMIN entries\n",
    "minTemps = df.filter(df.measure_type == \"TMIN\")\n",
    "\n",
    "# Select only stationID and temperature\n",
    "stationTemps = minTemps.select(\"stationID\", \"temperature\")\n",
    "\n",
    "# Aggregate to find minimum temperature for every station\n",
    "minTempsByStation = stationTemps.groupBy(\"stationID\").min(\"temperature\")\n",
    "minTempsByStation.show()\n",
    "\n",
    "# Convert temperature to fahrenheit and sort the dataset\n",
    "minTempsByStationF = minTempsByStation.withColumn(\"temperature\",\n",
    "                                                  func.round(func.col(\"min(temperature)\") * 0.1 * (9.0 / 5.0) + 32.0, 2))\\\n",
    "                                                  .select(\"stationID\", \"temperature\").sort(\"temperature\")\n",
    "                                                  \n",
    "# Collect, format, and print the results\n",
    "results = minTempsByStationF.collect()\n",
    "\n",
    "for result in results:\n",
    "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))\n",
    "    \n",
    "spark.stop()\n",
    "\n",
    "                                                  "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}