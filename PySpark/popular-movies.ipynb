{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"PopularMovies\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "lines = sc.textFile(\"data/ml-100k/u.data\")\n",
    "movies = lines.map(lambda x: (int(x.split()[1]), 1))\n",
    "movieCounts = movies.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "flipped = movieCounts.map( lambda xy: (xy[1],xy[0]) )\n",
    "sortedMovies = flipped.sortByKey()\n",
    "\n",
    "results = sortedMovies.collect()\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "sc.stop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Popular movies DF\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PopularMovies\").getOrCreate()\n",
    "\n",
    "# Create schema when reading u.data\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "\n",
    "# Load up movie data as dataframe\n",
    "moviesDF = spark.read.option(\"sep\", \"\\t\").schema(schema).csv(\"data/ml-100k/u.data\")\n",
    "\n",
    "# Some SQL-style magic to sort all movies by popularity in one line!\n",
    "topMovieIDs = moviesDF.groupBy(\"movieID\").count().orderBy(func.desc(\"count\"))\n",
    "\n",
    "# Grab the top 10\n",
    "topMovieIDs.show(10)\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Popular Movies nicer\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import codecs\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    # The following line is updated from what's in the video to handle\n",
    "    # encoding issues on some Ubuntu systems:\n",
    "    with codecs.open(\"ml-100k/u.ITEM\", \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"PopularMovies\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "nameDict = sc.broadcast(loadMovieNames())\n",
    "\n",
    "lines = sc.textFile(\"data/ml-100k/u.data\")\n",
    "movies = lines.map(lambda x: (int(x.split()[1]), 1))\n",
    "movieCounts = movies.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "flipped = movieCounts.map( lambda x : (x[1], x[0]))\n",
    "sortedMovies = flipped.sortByKey()\n",
    "\n",
    "sortedMoviesWithNames = sortedMovies.map(lambda countMovie : (nameDict.value[countMovie[1]], countMovie[0]))\n",
    "\n",
    "results = sortedMoviesWithNames.collect()\n",
    "\n",
    "for result in results:\n",
    "    print (result)\n",
    "\n",
    "sc.stop()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Popular movies nice DF\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "import codecs\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    # CHANGE THIS TO THE PATH TO YOUR u.ITEM FILE:\n",
    "    with codecs.open(\"E:/SparkCourse/ml-100k/u.ITEM\", \"r\", encoding='ISO-8859-1', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PopularMovies\").getOrCreate()\n",
    "\n",
    "nameDict = spark.sparkContext.broadcast(loadMovieNames())\n",
    "\n",
    "# Create schema when reading u.data\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "\n",
    "# Load up movie data as dataframe\n",
    "moviesDF = spark.read.option(\"sep\", \"\\t\").schema(schema).csv(\"data/ml-100k/u.data\")\n",
    "\n",
    "movieCounts = moviesDF.groupBy(\"movieID\").count()\n",
    "\n",
    "# Create a user-defined function to look up movie names from our broadcasted dictionary\n",
    "def lookupName(movieID):\n",
    "    return nameDict.value[movieID]\n",
    "\n",
    "lookupNameUDF = func.udf(lookupName)\n",
    "\n",
    "# Add a movieTitle column using our new udf\n",
    "moviesWithNames = movieCounts.withColumn(\"movieTitle\", lookupNameUDF(func.col(\"movieID\")))\n",
    "\n",
    "# Sort the results\n",
    "sortedMoviesWithNames = moviesWithNames.orderBy(func.desc(\"count\"))\n",
    "\n",
    "# Grab the top 10\n",
    "sortedMoviesWithNames.show(10, False)\n",
    "\n",
    "# Stop the session\n",
    "spark.stop()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}